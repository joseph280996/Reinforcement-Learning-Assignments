{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b95334",
   "metadata": {},
   "source": [
    "# Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137120e0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a75296",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from models.environment import Environment\n",
    "from models.policy import Policy\n",
    "from models.train import MonteCarloTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edee9ed",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Defining the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8a3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPACT_TRACK = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 0, 0, 2],\n",
    "    [1, 1, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 2],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0, 0, 2],\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0, 0, 2],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
    "    [1, 3, 3, 3, 3, 1, 1, 1, 1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c26c8",
   "metadata": {},
   "source": [
    "# Run the training and simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4631ebbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Environment' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     38\u001b[0m track, start_positions, finish_line \u001b[38;5;241m=\u001b[39m create_sample_track()\n\u001b[1;32m---> 39\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinish_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m policy \u001b[38;5;241m=\u001b[39m policy()\n\u001b[0;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m train(env, policy)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Environment' object is not callable"
     ]
    }
   ],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 10))\n",
    "        self.ax.set_xlim(0, env.width)\n",
    "        self.ax.set_ylim(0, env.height)\n",
    "        self.ax.invert_yaxis()\n",
    "\n",
    "    def plot_track(self):\n",
    "        self.ax.imshow(self.env.track, cmap='binary')\n",
    "        for pos in self.env.start_positions:\n",
    "            self.ax.add_patch(Rectangle((pos[1]-0.5, pos[0]-0.5), 1, 1, fill=False, edgecolor='g', lw=2))\n",
    "        for pos in self.env.finish_line:\n",
    "            self.ax.add_patch(Rectangle((pos[1]-0.5, pos[0]-0.5), 1, 1, fill=False, edgecolor='r', lw=2))\n",
    "\n",
    "    def plot_episode(self, episode: List[Tuple[Tuple[int, int, int, int], Tuple[int, int], float]]):\n",
    "        x, y = zip(*[(state[1], state[0]) for state, _, _ in episode])\n",
    "        self.ax.plot(x, y, 'b-', linewidth=2, alpha=0.5)\n",
    "        self.ax.plot(x[0], y[0], 'go', markersize=10)  # Start\n",
    "        self.ax.plot(x[-1], y[-1], 'ro', markersize=10)  # End\n",
    "\n",
    "    def show(self):\n",
    "        plt.show()\n",
    "\n",
    "    def clear_episode(self):\n",
    "        for line in self.ax.lines:\n",
    "            line.remove()\n",
    "\n",
    "def create_sample_track():\n",
    "    track = np.ones((20, 10), dtype=int)\n",
    "    for i in range(20):\n",
    "        track[i, max(0, 10 - i - 1):] = 0\n",
    "    start_positions = {(19, j) for j in range(10) if track[19, j] == 1}\n",
    "    finish_line = {(0, j) for j in range(10) if track[0, j] == 1}\n",
    "    return track, start_positions, finish_line\n",
    "\n",
    "# Example usage\n",
    "track, start_positions, finish_line = create_sample_track()\n",
    "env = env(track, start_positions, finish_line)\n",
    "policy = policy()\n",
    "trainer = train(env, policy)\n",
    "visualizer = Visualizer(env)\n",
    "\n",
    "visualizer.plot_track()\n",
    "visualizer.show()\n",
    "\n",
    "# Train and visualize progress\n",
    "num_episodes = 10000\n",
    "visualize_every = 1000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    if episode % visualize_every == 0:\n",
    "        test_episode = trainer.generate_episode()\n",
    "        visualizer.clear_episode()\n",
    "        visualizer.plot_track()\n",
    "        visualizer.plot_episode(test_episode)\n",
    "        visualizer.ax.set_title(f\"Episode {episode}\")\n",
    "        visualizer.show()\n",
    "    \n",
    "    trainer.train(1)\n",
    "\n",
    "# Final test run\n",
    "state = env.reset()\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "test_episode = []\n",
    "\n",
    "while True:\n",
    "    action = policy.get_action(state)\n",
    "    next_state, reward, done = env.step(state, action)\n",
    "    test_episode.append((state, action, reward))\n",
    "    total_reward += reward\n",
    "    steps += 1\n",
    "    if done:\n",
    "        break\n",
    "    state = next_state\n",
    "\n",
    "print(f\"Test run completed in {steps} steps with total reward {total_reward}\")\n",
    "\n",
    "visualizer.clear_episode()\n",
    "visualizer.plot_track()\n",
    "visualizer.plot_episode(test_episode)\n",
    "visualizer.ax.set_title(\"Final Test Run\")\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a996f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and training\n",
    "env = env.Environment(COMPACT_TRACK)\n",
    "policy = policy.Policy()\n",
    "trainer = train.MonteCarloTrainer(env, policy)\n",
    "\n",
    "num_episodes = 100000\n",
    "trainer.train(num_episodes)\n",
    "\n",
    "# Function to simulate and visualize a trajectory\n",
    "def simulate_trajectory(environment, policy, start_pos):\n",
    "    state = (start_pos, (0, 0))\n",
    "    trajectory = [state[0]]\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = policy.get_action(state)\n",
    "        next_state, _, done = environment.take_action(state, action)\n",
    "        trajectory.append(next_state[0])\n",
    "        state = next_state\n",
    "\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a5e77",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Plot the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919b598",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Visualize the track and some trajectories\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(COMPACT_TRACK, cmap='binary')\n",
    "plt.title(\"S-Curve Compact Racetrack with Optimal Trajectories\")\n",
    "\n",
    "colors = ['r', 'g', 'b', 'y', 'm']\n",
    "for i, start_pos in enumerate(env.start_line[:5]):  # Plot up to 5 trajectories\n",
    "    trajectory = simulate_trajectory(env, policy, start_pos)\n",
    "    xs, ys = zip(*trajectory)\n",
    "    plt.plot(ys, xs, color=colors[i], linewidth=2, label=f\"Trajectory {i+1}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904f519",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs138_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
