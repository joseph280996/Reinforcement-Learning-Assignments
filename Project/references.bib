@misc{huggingface_dql,
    title = {The Deep Q-Learning Algorithm},
    author = {Hugging Face},
    year = {2023},
    howpublished = {\url{https://huggingface.co/learn/deep-rl-course/unit3/deep-q-learning}},
    note = {Hugging Face Deep RL Course},
    url = {https://huggingface.co/learn/deep-rl-course/unit3/deep-q-learning}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{liniger2015optimization,
  title={Optimization-based autonomous racing of 1: 43 scale RC cars},
  author={Liniger, Alexander and Lygeros, John and Apkarian, Pierre},
  booktitle={2015 European Control Conference (ECC)},
  pages={586--591},
  year={2015},
  organization={IEEE}
}

@article{saxena2020driving,
  title={Driving in the matrix: Can virtual worlds replace human-generated annotations for real world tasks?},
  author={Saxena, Abhinav and Isola, Phillip and others},
  journal={arXiv preprint arXiv:2004.06477},
  year={2020}
}

@inproceedings{wurman2002racing,
  title={Racing against opponents with approximate predictive state representations},
  author={Wurman, Peter R and D'Andrea, Raffaello and Mountz, Mick},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  pages={523--528},
  year={2002},
  organization={Citeseer}
}
@book{sutton-barton-rl,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.}
}

